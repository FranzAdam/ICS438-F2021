{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d5f875",
   "metadata": {},
   "source": [
    "### Identifying similar items\n",
    "\n",
    "* A fundamental problem in data mining is to search for \"similar\" items.\n",
    "* E.g.: \n",
    "    * Finding duplicate Web pages \n",
    "    * Finding duplicate listings on an e-commerce platform (e.g., Craigslist or Amazon)\n",
    "   \n",
    "* How do we find very closely related items to a given query $q$\n",
    "* We often need to do that for all instances of a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b0027",
   "metadata": {},
   "source": [
    "### Native Solution\n",
    "\n",
    "* Compare items pairwise and compute some score of similarity between the pages.\n",
    "\n",
    "* A naive approach is not tractable.\n",
    "\n",
    "* For n items there are $\\frac{n \\times (n-1)}{2} \\in O(n^2)$ unique comparisons\n",
    "  * With 1 million items, there are 4,999,9950,0000 comparisons\n",
    "    * That's a relatively small dataset by today's standard\n",
    "  * May be computationally intractable or cost-prohibitive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f144319d",
   "metadata": {},
   "source": [
    "### Score of Between Two Items\n",
    "\n",
    "* Suppose we have two records (instances) for a dataset\n",
    "  * Records contain `marital_status`, `number of children`, `has_investments?`, `owns_house?`, `car >= 2?`\n",
    "\n",
    "```python    \n",
    " a = [\"Married\", \"4\", \"yes\", \"yes\", \"yes\"]\n",
    " b = [\"Married\", \"2\", \"yes\", \"yes\", \"yes\"]\n",
    " c = [\"Single\",  \"0\", \"yes\", \"no\", \"no\"]\n",
    " ``` \n",
    "* How similar are the following sets?\n",
    "* We can see that `a` and `b` are more alike than `a` and `c` or `a` and `d`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3c9832",
   "metadata": {},
   "source": [
    "### Similarity Between two Sets\n",
    "\n",
    "```python\n",
    " a = [\"Married\", \"4\", \"yes\", \"yes\", \"yes\"]\n",
    " b = [\"Married\", \"2\", \"yes\", \"yes\", \"yes\"]\n",
    "```\n",
    "\n",
    "* One way to capture the similarity is by comparing the number of shared features\n",
    "* `a` and `b share 4 similar values out of 5.\n",
    "* `a` and `c` share 1 similar value out of 5.\n",
    "\n",
    "* We can therefore say that `a` and `b` are more similar than `a and c` or `b` and `c`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87914ca0",
   "metadata": {},
   "source": [
    "### Jaccard Similarity\n",
    "\n",
    "* We define the Jaccard similarity between two sets $S$ and $T is \n",
    "\n",
    "$$\n",
    "J(S,T) = \\frac{|S \\cap T |}{|S \\cup T |}\n",
    "$$\n",
    "\n",
    "  * i.e., the size of the intersection of S and T to the size of their union. \n",
    "\n",
    "* $J(a,b) = 4/5 = 0.8$\n",
    "* $J(a,c) = 1/5 = 0.2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af01becf",
   "metadata": {},
   "source": [
    "### Hashing\n",
    "\n",
    "* Many applications depend critically on quickly finding items in a list\n",
    "  * We cannot afford to search for the item (Binary search is $O(logN)$ where N is the number of items to search) \n",
    "  * E.g.: air traffic control or packet routing in critical web applications\n",
    "* Hashing can yield a match in near-constant time O(1)\n",
    "  * The cost to compute the hash is constant\n",
    "\n",
    "* Idea: \n",
    "  1. Transform the searched-for item into some index (key)\n",
    "    * We can compute the `key` of an element `e` using a funciton `key()`\n",
    "    * `key(e)= k`\n",
    "  2. Find the index in a table (table)\n",
    "    * Use the hash function to determine bin (`b`) in a table where `k` belongs.\n",
    "    * `hash(b)= b`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9d3145",
   "metadata": {},
   "source": [
    "### Hashing -- Cont'd \n",
    "<img src=\"https://www.dropbox.com/s/tkk8tz0yy6k7v2q/hashing.png?dl=1\" alt=\"Drawing\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9d843bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('d3b4ca42-4e67-4214-87d2-afa9bda02dd1')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Universally Unique Identifier (UUID) \n",
    "### are often used to identify objects in software\n",
    "### Paricularly in\n",
    "import uuid\n",
    "uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2395fde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['963b0a6c-8903-4679-9f8b-275a9016b3bb',\n",
       " '26a15468-6553-4109-83c3-2054e647c80d',\n",
       " '9a2042e0-2ff3-4cc2-93ae-8ae31c97cc84',\n",
       " 'daa18486-2b03-416e-b95d-38ecc972f6e5',\n",
       " 'e317b08e-4d02-445e-a703-ada8db21c990']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uuid_list = []\n",
    "for val in range(5):\n",
    "    uuid_list.append(str(uuid.uuid4()))\n",
    "uuid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f42b8f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['692b9e2e-d013-4c25-b021-63b8c58b70f9',\n",
       " 'efead027-7e51-4d64-bd35-608f22f71a27',\n",
       " 'd9403ccc-2a25-42b1-876f-1362c51a3203',\n",
       " 'b3804ba9-d330-4749-b3c1-c053de49cf6f',\n",
       " '906f5464-003d-4099-adb1-dd3f2bef1c85']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following uses a list comprehension.\n",
    "# List comprehensions are useful and terse to write \n",
    "# See https://realpython.com/list-comprehension-python/\n",
    "uuid_list = [str(uuid.uuid4()) for i in range(5)] \n",
    "uuid_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a75b2d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('86e0328c-bddd-4391-8f19-120a19e5daf0', 1630362119.9827042),\n",
       " ('2eb1ebf7-d9c7-4ea6-bb0d-08894576860a', 1630362119.9827478),\n",
       " ('eaef2ba6-299e-46bf-82b1-1092a1c723c3', 1630362119.9829571),\n",
       " ('871da3d1-1a62-4c22-aae8-f62a429e5e48', 1630362119.983126),\n",
       " ('075ff174-eda5-44ae-b0dc-fa199859cca8', 1630362119.983145)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "import time\n",
    "uuid_list = [(str(uuid.uuid4()), time.time()) for i in range(5)] \n",
    "uuid_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e7c7932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.82 s, sys: 1.82 s, total: 6.64 s\n",
      "Wall time: 6.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "uuid_list = [(str(uuid.uuid4()), time.time()) for i in range(1_000_000)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c7507bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9b18a5d8-c350-479e-95bb-90c69778ef51'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uuid_list[999999][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9805e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('9b18a5d8-c350-479e-95bb-90c69778ef51', 1630362168.9442601)\n",
      "CPU times: user 138 ms, sys: 6.88 ms, total: 145 ms\n",
      "Wall time: 157 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = uuid_list[999999][0]\n",
    "for elem in uuid_list:\n",
    "    if elem[0] == query:\n",
    "        print(elem)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdcb168a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 85 ms, sys: 3.34 ms, total: 88.4 ms\n",
      "Wall time: 88.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('9b18a5d8-c350-479e-95bb-90c69778ef51', 1630362168.9442601)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "[x for x in uuid_list if x[0] == query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "600a90bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "802843"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(0, 999_999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ca212c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'749498b1-e22b-4a62-b56f-8aa2592c5bdf'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = random.randint(0, 999_999)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cbe3d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21b52a7f-71e5-468a-9018-660e9ebe366c',\n",
       " 'b1bd5f9f-d4e9-4f43-9b9e-f5a952a43486',\n",
       " '6d93aa39-208b-48d6-90bd-e045e1a6309e',\n",
       " '8495b51d-e28f-431c-8a70-28138a4e931c']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = []\n",
    "for i in range(100):\n",
    "    rand_position = random.randint(0, 999_999)\n",
    "    query = uuid_list[rand_position][0]\n",
    "    queries.append(query)\n",
    "\n",
    "queries[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96a260c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.81 s, sys: 116 ms, total: 6.92 s\n",
      "Wall time: 7.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for q in queries:\n",
    "    temp = [x for x in uuid_list if x[0] == q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fac89b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 1, 'B': 2, 'C': 3}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can easily build a dict from a list of tuples\n",
    "dict([(\"A\", 1), (\"B\", 2), (\"C\", 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa11ca05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can easily build a dict from a list of tuples\n",
    "some_dict = dict([(\"A\", 1), (\"B\", 2), (\"C\", 3)])\n",
    "some_dict[\"B\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f6a3701",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid_hash = dict(uuid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0801dc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query is: 21b52a7f-71e5-468a-9018-660e9ebe366c\n",
      "The time associated with q is 1630362166.3199518\n"
     ]
    }
   ],
   "source": [
    "q = queries[0]\n",
    "print(f\"The query is: {q}\")\n",
    "print(f\"The time associated with q is {uuid_hash[q]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06fc4bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 102 µs, sys: 15 µs, total: 117 µs\n",
      "Wall time: 158 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for q in queries:\n",
    "    uuid_hash[q]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0675b4a",
   "metadata": {},
   "source": [
    "### The Hash Function in Python\n",
    "\n",
    "* Python uses `hash()` to hash an immutable object\n",
    "  * Combine conversion of input to a key and hash of key to a bin\n",
    "  * Cannot hash any object that can be modified, such as lists\n",
    "  * The has value is used to determine the location (address) where a dict key will be stored\n",
    "  \n",
    "```python\n",
    "    hash()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8956078",
   "metadata": {},
   "source": [
    "### Hashing Similar Items\n",
    "\n",
    "* The following dataset contains individuals' info\n",
    "  * `name`, `age`, `salary`, and `number of years of experience`\n",
    "\n",
    "```python\n",
    "data_1 = (\"John\", \"Doe\", \"32\", \"165,385\", 3)\n",
    "data_2 = (\"Jane\", \"Doe\", \"32\", \"192,891\", 3)\n",
    "data_3 = (\"Mark\", \"Smith\", \"34\", \"85,232\", 2)\n",
    "```\n",
    "\n",
    "* We can hash each of these datasets using the `hash` function.\n",
    "  * Note that I declared them as tuples instead of lists\n",
    "  * Lists are mutable and, therefore, not hashable\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a73a4d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hash for data_1 is -4963267576972147216\n",
      "The hash for data_2 is 2507519308106365574\n",
      "The hash for data_3 is 8273363848522466991\n",
      "The hash for data_4 is -2065029817041674176\n"
     ]
    }
   ],
   "source": [
    "data_1 = (\"John\", \"Doe\", \"32\", \"165,385\", 3)\n",
    "print(f\"The hash for data_1 is {hash(data_1)}\")\n",
    "\n",
    "data_2 = (\"Mat\", \"Doe\", \"32\", \"192,891\", 3)\n",
    "print(f\"The hash for data_2 is {hash(data_2)}\")\n",
    "\n",
    "data_3 = (\"Mark\", \"Smith\", \"34\", \"85,232\", 2)\n",
    "print(f\"The hash for data_3 is {hash(data_3)}\")\n",
    "\n",
    "data_4 = (\"Mindy\", \"Smith\", \"65\", \"160,000\", 42)\n",
    "print(f\"The hash for data_4 is {hash(data_4)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ac123",
   "metadata": {},
   "source": [
    "### Hashing and Proximity\n",
    "\n",
    "* We've shown that hashing can be much faster for finding identical items than a search\n",
    "\n",
    "* Unfortunately, hashing does not convey level of similarity (e.g.: using Jaccard) \n",
    "  * `data_1` and `data_2` are closer to each other than to `data_3`, but their hashes are not\n",
    "* Can we use hashing to convey some level of similarity?\n",
    "  * We could find potentially similar items using hashing (fast) and then compare the subset of items using Jaccard similarity?\n",
    "  * Pairwise comparison on a much smaller subset of data\n",
    "\n",
    "  \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826bd9cd",
   "metadata": {},
   "source": [
    "### Hashing and Proximity - cont'd\n",
    "\n",
    "* Naive approach: normalize values to convey similarity\n",
    "\n",
    "1. Drop non-relevant unnecessary columns such as first and last name\n",
    "    * for instance, one could start by de-replicating highly-correlated variables.\n",
    "    * use domain knowledge to remove features that can be derived from other features\n",
    "2. Convert numerical values into bins\n",
    "3. Compare the entries over the converted data\n",
    "    * Compute the hash on some randomly picked subset of features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a850e27f",
   "metadata": {},
   "source": [
    "### Hashing and Proximity -1\n",
    "\n",
    "```python\n",
    "# original data\n",
    "data_1 = (\"John\", \"Doe\", \"32\", \"165,385\", 3)\n",
    "data_2 = (\"Mat\", \"Doe\", \"32\", \"192,891\", 3)\n",
    "data_3 = (\"Mark\", \"Smith\", \"34\", \"85,232\", 2)\n",
    "data_4 = (\"Mindy\", \"Smith\", \"65\", \"160,000\", 42)\n",
    "\n",
    "# Binned data\n",
    "\n",
    "data_1 = (\"milenial\", \"high\", \"low\")\n",
    "data_2 = (\"milenial\", \"high\", \"low\")\n",
    "data_3 = (\"millenial\", \"average\", \"low\")\n",
    "data_4 = (\"baby_boomer\", \"high\", \"high\")\n",
    "```\n",
    "\n",
    "* This approach supposes it's possible to bin the data into relevant categories\n",
    "  * Here we can create relative significant categories that may be satisfactory to find matching profiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de3dec78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('milenial', 'high', 'low'),\n",
       " ('milenial', 'high', 'low'),\n",
       " ('millenial', 'average', 'low'),\n",
       " ('baby_boomer', 'high', 'high')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = [(\"milenial\", \"high\", \"low\"), (\"milenial\", \"high\", \"low\"), (\"millenial\", \"average\", \"low\"), (\"baby_boomer\", \"high\", \"high\")]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "592da1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-3698440417353788935,\n",
       " -3698440417353788935,\n",
       " 2874479796741313694,\n",
       " 1587425536473110470]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[hash(i) for i in d]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514becc1",
   "metadata": {},
   "source": [
    "### Hashing and Proximity -2\n",
    "\n",
    "* When workign with large datasets (particulalry wide) and comparing the data across all the features may be CPU and disk intensive.\n",
    "\n",
    "* For example, image an isntance (singel entry) that has thousands of features\n",
    "  * Example 1: a simple way to numericize a documnt is by representing it a counts of its word occurrences\n",
    "  * Example 2: DNA testing companies can assay hundreds of thousands of genetic markers\n",
    "  * example 3: A medical expertiment, for each patient, one can record:\n",
    "      - Age\n",
    "      -  blood analysis:\n",
    "        - Complete blood count\n",
    "        - High Density Lipoprotein (HDL)\n",
    "        - Low Density Lipoprotein (LDL)\n",
    "        - White Blood Cell Count\n",
    "        - Red Blood Cell Count\n",
    "        - ...\n",
    "      - Immune system status\n",
    "        - Number of leukocytes\n",
    "        - Cytokine levels in serum\n",
    "        - ....\n",
    "      - Genetic background\n",
    "      - nb cigarettes in last month\n",
    "      - nb of alcoholic drinks in last month\n",
    "      - nb times used drugs in last month\n",
    "      - nb surgical operations in last year\n",
    "      - nb of medications taken\n",
    "      - nb of hospital visits\n",
    "      - ...\n",
    "  \n",
    "  \n",
    "  \n",
    "* It's dificult to compare data across all features \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212f24a9",
   "metadata": {},
   "source": [
    "### Hashing and Proximity\n",
    "\n",
    "* Recall that the objective we defined above is to find items that are similar to a query $q$ \n",
    "* The proposed subset-bin approach is not a perfect replacement for pairwise comparisons but allows us to avoid unnecessary comparisons\n",
    "  * We only focus on pairs of items that generate matches \n",
    "* it's also ideal for dealing with very wide datasets\n",
    "   * In a dataset with thousands of features, we need only focus on a small subset of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764e6981",
   "metadata": {},
   "source": [
    "### Hashing Wide Datasets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* While this is computationally efficient, there is a risk that we might choose the wrong features\n",
    "    \n",
    "```python \n",
    "         [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "data_1 = [x, x, x, x, y, x, x, y]\n",
    "data_2 = [x, x, x, x, z, x, x, z]\n",
    "data_3 = [w, w, w, w, z, w, w, z]\n",
    "```\n",
    " * e.g.: randomly picking features 5 and 8 can miss identification of the closest item."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3537045",
   "metadata": {},
   "source": [
    "### Hashing Wide Datasets - cont'd\n",
    "\n",
    "* Perhaps we can repeat the algorithm multiple times\n",
    "\n",
    "1. Pick a random subset of features\n",
    "2. compute the hash on the selected subset of features\n",
    "3. Repeat a certain number of times\n",
    "\n",
    "* There are theoretical guarantees that can make this work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7ba2e",
   "metadata": {},
   "source": [
    "### Iterative Hashing\n",
    "\n",
    "* Given two datasets with $N$ features and $K$ features that match between $x_i$ and $x_j$\n",
    "* If we hash on $n$ features, we can compute the probability of a matching hash value\n",
    "  * We are selecting $n$ features and we want the probability that all $n$ features match\n",
    "\n",
    "\n",
    "![](https://www.dropbox.com/s/c7bbp98fhcn0s0q/select_jar.png?dl=0)\n",
    "\n",
    "$$\n",
    "p = \\frac{{K}\\choose{n}}{{N}\\choose{n}}\n",
    "$$\n",
    "\n",
    "\n",
    "* This is a specific case of the hypergeometric distribution (https://en.wikipedia.org/wiki/Hypergeometric_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee06106",
   "metadata": {},
   "source": [
    "### Iterative Hashing - Single iteration Probability\n",
    "\n",
    "e.g.: \n",
    "    \n",
    "* Suppose we have a dataset that has 100 features\n",
    "* Given two instances $x_i$ and $x_j$ that match over 95 of the features \n",
    "* what is the probability that x_i and x_j match on a randomly selected subset of 6 features?\n",
    "\n",
    "$$\n",
    "p = \\frac{{K}\\choose{n}}{{N}\\choose{n}} = \\frac{{95}\\choose{6}}{{100}\\choose{6}}\n",
    "$$\n",
    "\n",
    "* in Python\n",
    "\n",
    "```python\n",
    "math.comb(95, 6) / math.comb(100, 6) = 0.72908\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618bf73a",
   "metadata": {},
   "source": [
    "### Iterative Hashing - Probability for Multiple iterations \n",
    "\n",
    "* The probability of two relatively similar instances matching may not be acceptable\n",
    "  * p=0.73 means that we may miss up to ~27% of the instances that are similar to a query\n",
    " \n",
    "* Repeating the process multiple times increases our chances of selecting $n$ features that match between $x_i$ and $x_j$\n",
    "\n",
    "\n",
    "\n",
    "* Specifically, given the probability of a single match (ex. p=0.73), repeating the process $n$ times means that the probability of at least one match is:\n",
    "\n",
    "$$\n",
    "1- (1-p)^{n}\n",
    "$$\n",
    "\n",
    "* This is based on the binomial probability distribution\n",
    "https://en.wikipedia.org/wiki/Binomial_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc48209",
   "metadata": {},
   "source": [
    "### Iterative Hashing - Probability for Multiple iterations \n",
    "\n",
    "* The probability for a single perfect match in the example above is p=0.73\n",
    "\n",
    "* The probability of at least one match in 10 trials is $1 - (1-0.73)^{10}$\n",
    "\n",
    "* in Python\n",
    "\n",
    "```\n",
    "1 - (1-0.73)**10 = 0.9999979\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e2dacf",
   "metadata": {},
   "source": [
    "### Simulating the probabilities.\n",
    "\n",
    "* A relatively tractable way to estimate probabilities for simple events is through simulation.\n",
    "\n",
    "E.g.: \n",
    "* Suppose we have a dataset that has 100 features \n",
    "* Given two instances $x_i$ and $x_j$ that match on 95 out of 100  features \n",
    "* What is the probability that x_i and x_j match on a randomly selected subset of 6 features?\n",
    "  * Randomly select 6 features a large number of times and compute the fraction of times you obtained a perfect match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd45c7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "y is: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# intially x and y match\n",
    "x = [1 for i in  range(100)]\n",
    "y = [1 for i in  range(100)]\n",
    "print(f\"x is: {x}\\n\")\n",
    "print(f\"y is: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f3b92ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[89, 80, 44, 2, 38]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select 5 positions where x and y will not match\n",
    "import random\n",
    "\n",
    "random_positions = random.sample(range(100), 5)\n",
    "random_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "174525a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# change the values in y at the selected positions\n",
    "for i in random_positions:\n",
    "    y[i] = 0\n",
    "    \n",
    "print(x)    \n",
    "print(y)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "00d2af94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 85, 16, 43, 81, 28]\n",
      "(1, 1, 1, 1, 1, 1)\n",
      "(1, 1, 1, 1, 1, 1)\n",
      "-1276324167427414696\n",
      "-1276324167427414696\n"
     ]
    }
   ],
   "source": [
    "random_columns = random.sample(range(100), 6)\n",
    "print(random_columns)\n",
    "values_for_x = tuple([x[random_columns[0]], x[random_columns[1]], x[random_columns[2]],  x[random_columns[3]], x[random_columns[4]], x[random_columns[5]]])\n",
    "values_for_y = tuple([y[random_columns[0]], y[random_columns[1]], y[random_columns[2]],  y[random_columns[3]], y[random_columns[4]], y[random_columns[5]]])\n",
    "print(values_for_x)\n",
    "print(values_for_y)\n",
    "print(hash(values_for_x))\n",
    "print(hash(values_for_y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fb661939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72852\n"
     ]
    }
   ],
   "source": [
    "\n",
    "perfect_matches = 0\n",
    "\n",
    "for _ in range(100_000):\n",
    "    comparison_indices = random.sample(range(100), 6)\n",
    "    nb_matches = sum([x[i] == y[i] for i in comparison_indices])\n",
    "    if nb_matches == 6:\n",
    "        perfect_matches += 1 \n",
    "        \n",
    "print(perfect_matches/100_000)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "482ac628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can simulate an event of that has a probability of p \n",
    "# by simulating a coing flip\n",
    "\n",
    "random.choices([0, 1], weights=[0.27, 0.73])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "507fac55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 0, 0, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "outcomes = []\n",
    "for i in range(10):\n",
    "    outcomes.append(random.choices([0, 1], weights=[0.27, 0.73])[0])\n",
    "print(outcomes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ccd55ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def has_a_success(prob):\n",
    "    outcomes = []\n",
    "    for i in range(10):\n",
    "        outcomes.append(random.choices([0, 1], weights=[1-prob, prob])[0])\n",
    "    if sum(outcomes) > 0:\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "32e06cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_a_success(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fcf7f092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_a_success(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "89de4537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "nb_successes = 0\n",
    "\n",
    "prob = 0.73\n",
    "\n",
    "for i in range(100_000):\n",
    "    if has_a_success(prob):\n",
    "        nb_successes +=1 \n",
    "        \n",
    "print(nb_successes/100_000)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b89ba5",
   "metadata": {},
   "source": [
    "### Variables and Dimensionality\n",
    "\n",
    "* The approach above required \"binning\" the data to maximize matches. What\n",
    "* This approach works well when binning is possible or when the data is binary\n",
    "  * For example when working with presence-absence.\n",
    "* This solution is not practical when bin boundaries are not easy to derive\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af19ef65",
   "metadata": {},
   "source": [
    "### Data in Higher-Dimensional Space\n",
    "\n",
    "\n",
    "* Another approach for finding similar items requires thinking of the data in higher-dimensional space.\n",
    "\n",
    "* The data features are simply dimensions in space.\n",
    "  * The instances of a dataset with two features can be plotted in 2-D space. \n",
    "  * The instances of a dataset with three features can be plotted in 3-D space. \n",
    "  * The instances of a dataset with n features can be plotted in n-D space. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1108960",
   "metadata": {},
   "source": [
    "### Data in 2D\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/t0ca5t1qzkr635b/2d-data.png?dl=1\" alt=\"Drawing\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94032748",
   "metadata": {},
   "source": [
    "### Data in 3D\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/4flfaojlfb2a101/3d-data.png?dl=1\" alt=\"Drawing\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f54e333",
   "metadata": {},
   "source": [
    "### Random Projections: An intuition\n",
    "\n",
    "* Instead of hashing the data, let's project it into a new line instead.\n",
    "\n",
    "    * Given some randomly selected line, project a point so that the projection is perpendicular to the projection line\n",
    "\n",
    "* Two point that are close in higher dimensional space *may* also be close on the line\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/pjmbski6b0v8s8y/point_3d.png?dl=1\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a20ad25",
   "metadata": {},
   "source": [
    "### Random Projections: An intution - Cont'd\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/vkmv5um7w256w33/3d_point_line.png?dl=1\" alt=\"Drawing\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d8d1fb",
   "metadata": {},
   "source": [
    "### Random Projections: An intution - Cont'd\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/irik02lzrkuykgp/projection_1.png?dl=1\" alt=\"Drawing\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85caea49",
   "metadata": {},
   "source": [
    "### Random Projections: An intution - Cont'd\n",
    "\n",
    "* Intuition: two points that are projected close to each other (say to the same line bin) are potentially similar and should be inspected further\n",
    "  * This is somewhat a relaxed version of hashing since instances don't need to hash to the same value \n",
    "     * Projecting close to each other in the same bin is sufficient\n",
    "* We also don't need to bin the feature values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b813253",
   "metadata": {},
   "source": [
    "### Random Projections: An intution - Cont'd\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/8y35229n7sb66ep/projection_2.png?dl=1\" alt=\"Drawing\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9105b85d",
   "metadata": {},
   "source": [
    "### Random Projections: An intution - Cont'd\n",
    "<span style=\"color:lightgrey;\">\n",
    "    \n",
    "### Random Projections: An intution - Cont'd\n",
    "\n",
    "* Intuition: two points that are projected close to each other (say to the same line bin) are potentially similar and should be inspected further\n",
    "  * This is somewhat a relaxed version of hashing since instances don't need to hash to the same value \n",
    "    * Projecting close to each other in the same bin is sufficient\n",
    "    * We also don't need to bin the feature values\n",
    "</span>\n",
    "    \n",
    "\n",
    "* Since the lines are randomly selected two close points may still fall into separate bins\n",
    "* To compensate, we can repeat the process multiple times\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c4b7a",
   "metadata": {},
   "source": [
    "### Projection Example \n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/irik02lzrkuykgp/projection_1.png?dl=1\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288084e6",
   "metadata": {},
   "source": [
    "### Projection Example - Cont'd\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/8y35229n7sb66ep/projection_2.png?dl=1\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277d1202",
   "metadata": {},
   "source": [
    "### Projection Example - Cont'd\n",
    "\n",
    "* Exmaple in 2-D\n",
    "<img src=\"https://www.dropbox.com/s/9szk1c2p0bvvacp/projection_3.png?dl=1\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e875d6",
   "metadata": {},
   "source": [
    "###  Projection as a Dot Product\n",
    "\n",
    "\n",
    "* How do you project a point onto a new axis?\n",
    " \n",
    "*  The dot product (or inner product) of two vectors is the projection of one onto the line spanned by the other.\n",
    "\n",
    "* It describes the projected vector in terms of the reference vector\n",
    "  * After normalizing, we get a quantity that represents the magnitude of the projected vector in terms of the reference vector\n",
    "\n",
    "$$\n",
    "Proj_B~A = \\frac{A \\cdot B}{|B|}\n",
    "$$\n",
    "where $A \\cdot B$ is simply the dot product of A and B.\n",
    "\n",
    "\n",
    "$A \\cdot B = A_x \\times B_x + A_y \\times B_y$ \n",
    "\n",
    "and $|B|$ is the magnitude of |B|. This is needed to normalize the resulting quantity (express it in terms of vector B)\n",
    "\n",
    "$|B| = \\sqrt{B_x^2 + B_y^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fe2ed949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The magnitude of B is: 5.385164807134504\n",
      "The magnitude of the projection  4.270992778072193\n",
      "The ration of the projection in terms of B is 0.7931034482758621\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# compute the normalized projection of A onto B.\n",
    "A = (3,4)\n",
    "B = (5,2)\n",
    "\n",
    "A_dot_B = A[0]*B[0] + A[1]*B[1]\n",
    "amp_B = math.sqrt(B[0]**2 + B[1]**2)\n",
    "print(f\"The magnitude of B is: {amp_B}\")\n",
    "proj = A_dot_B / amp_B\n",
    "print (f\"The magnitude of the projection  {proj}\")\n",
    "\n",
    "print(f\"The ratio of the projection in terms of B is {proj/amp_B}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73e7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (A_dot_B / amp_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7351863b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The magnitude of D is: 4.47213595499958\n",
      "\n",
      "The magnitude of the projection  4.427414595449584\n",
      "The ratio of the projection in terms of D is 0.99\n",
      "Projection occurs in bin 1 \n",
      "\n",
      "The magnitude of the projection  7.602631123499284\n",
      "The ratio of the projection in terms of D is 1.6999999999999997\n",
      "Projection occurs in bin 2 \n",
      "\n",
      "The magnitude of the projection  8.497058314499201\n",
      "The ratio of the projection in terms of D is 1.9\n",
      "Projection occurs in bin 2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Projection as a Dot Product\n",
    "\n",
    "A = (0.95, 8)\n",
    "B = (5,7)\n",
    "C = (6,5)\n",
    "D = (4,2)\n",
    "\n",
    "amp_D = math.sqrt(D[0]**2 + D[1]**2)\n",
    "print(f\"The magnitude of D is: {amp_D}\\n\")\n",
    "\n",
    "\n",
    "A_dot_D = A[0]*D[0] + A[1]*D[1]\n",
    "proj_A = A_dot_D / amp_D\n",
    "print (f\"The magnitude of the projection  {proj_A}\")\n",
    "print(f\"The ratio of the projection in terms of D is {proj_A/amp_D}\")\n",
    "print(f\"Projection occurs in bin {math.ceil(proj_A/amp_D)} \\n\")\n",
    "\n",
    "\n",
    "B_dot_D = B[0]*D[0] + B[1]*D[1]\n",
    "proj_B = B_dot_D / amp_D\n",
    "print (f\"The magnitude of the projection  {proj_B}\")\n",
    "print(f\"The ratio of the projection in terms of D is {proj_B/amp_D}\")\n",
    "print(f\"Projection occurs in bin {math.ceil(proj_B/amp_D)} \\n\")\n",
    "\n",
    "\n",
    "C_dot_D = C[0]*D[0] + B[1]*D[1]\n",
    "proj_C = C_dot_D / amp_D\n",
    "print (f\"The magnitude of the projection  {proj_C}\")\n",
    "print(f\"The ratio of the projection in terms of D is {proj_C/amp_D}\")\n",
    "print(f\"Projection occurs in bin {math.ceil(proj_C/amp_D)} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b266e3b",
   "metadata": {},
   "source": [
    "### Formalism Behind Random Projections \n",
    "\n",
    "\n",
    "* The theory (Johnson-Lindenstrauss lemma) behind random projections guarantees approximate preservation of distance \n",
    "\n",
    "* We can project on a lower number of dimensions without distorting the distance between any two points by more than a factor of (1 $\\pm$ $\\varepsilon$)\n",
    "\n",
    "  * Where $\\varepsilon$ depends on the number of instances in the data\n",
    "\n",
    "https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca6f611",
   "metadata": {},
   "source": [
    "### Implementation Details\n",
    "\n",
    "  \n",
    "* If input is $n \\times d$ matrix $A$.\n",
    "\n",
    "* using an __appropriate__ a $d \\times k$ matrix $R$, we can define the projection of $A$ as:\n",
    "$$\n",
    "E = A R\n",
    "$$\n",
    "\n",
    "* Therefore, the matrix multiplication $A \\dot R$ projects each of our data points onto the random vectors in $\\mathbb{R}$.\n",
    "\n",
    "* Normalise by the vector's magnitude and take ceiling (or floor) of these values to get the bin each instance falls into\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9469ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example of Random projections in Action \n",
    "https://github.com/spotify/annoy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
