{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a75fe00",
   "metadata": {},
   "source": [
    "### Python functionality for Map-Reduce\n",
    "\n",
    "* Python provides functionality similar to that covered in our Map-Reduce example. We need to:\n",
    "  * `map` key to initial values\n",
    "  * `filter` some of the data if needed\n",
    "  * `reduce` the data\n",
    "  * The three operations above can be implemented using Python's `map`, `filter` and `reduce`\n",
    "    * The latter is available in the `functools` packages\n",
    "\n",
    "\n",
    "* We also need to provide custom functionality to describe how the map, filter and reduce work\n",
    "  * Tedious to write functions, so we will anonymous functions (lambda function in Python)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b52a377",
   "metadata": {},
   "source": [
    "### Lambda Functions in Python\n",
    "\n",
    "* Anonymous functions (i.e. functions defined without a name) are constructed using the \"lambda\" keyword\n",
    "\n",
    "* The general structure of a lambda function is:\n",
    "```\n",
    "lambda <args>: <exprs>\n",
    "\n",
    "* They can only return a single expression\n",
    "* Does not need an explicit `return`\n",
    "  * The expression is returned by default\n",
    "* Lambda is a powerful concept in Python.\n",
    "    * Lambda functions come from functional programming languages and the Lambda Calculus.\n",
    "    * Not the same as `lambda` in functional programming languages, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0103655d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instead of  \n",
    "def f (x): \n",
    "   return x**2\n",
    "\n",
    "f(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed0107e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# you can assign a function to a variable\n",
    "g = lambda x: x**2\n",
    "g(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e07b939c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or simply \n",
    "# parenthesis around lambda provide to indicate where\n",
    "# function starts and stops\n",
    "(lambda x: x**2)(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58473e1e",
   "metadata": {},
   "source": [
    "### Lambda functions\n",
    "\n",
    "* Prevalent in Python.\n",
    "* Some functions take as input other functions as parameters. E.g.:\n",
    "    * `sorted` can take a lambda function to change the sort befhavior\n",
    "    * callback paradigm\n",
    "      * Do something asynchronous or long running and when done call the function passed as a argument\n",
    "* Common to pass lambda functions to `map`, `filter` and `reduce` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3f816a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dave', 'B', 10),\n",
       " ('jane', 'B', 12),\n",
       " ('john', 'A', 15),\n",
       " ('mary', 'A', 20),\n",
       " ('mary', 'A', 20)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sortd example\n",
    "student_tuples = [\n",
    "    ('john', 'A', 15),\n",
    "    ('mary', 'A', 20),\n",
    "    ('jane', 'B', 12),\n",
    "    ('dave', 'B', 10),\n",
    "    ('mary', 'A', 20),\n",
    "]\n",
    "\n",
    "sorted(student_tuples, key=lambda student: student[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552dd638",
   "metadata": {},
   "source": [
    "### Lambda function as arguments to `sorted`\n",
    "* The argument to sorted (lambda function) is called for each item in the iterable\n",
    "  * Here, the input to each call of the lambda function is a triplet.\n",
    "  * The output is the item on which we want to sort\n",
    "    * I.e., item 3 (item at index 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23dd2252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing someting with input 4\n",
      "Working....\n",
      "Done and the result is 2.0\n"
     ]
    }
   ],
   "source": [
    "# callback example\n",
    "import time\n",
    "\n",
    "def notify_me(result):\n",
    "    print(f\"Done and the result is {result}\")\n",
    "\n",
    "def do_work(data):\n",
    "    print(f\"Doing someting with input {data}\")\n",
    "    print(f\"Working....\")\n",
    "\n",
    "    time.sleep(5)\n",
    "    \n",
    "    result= data / 2\n",
    "    \n",
    "    return result\n",
    "\n",
    "    \n",
    "def handle_long_running(process, data, callback, ):\n",
    "    result = do_work(data)  \n",
    "    callback(result)\n",
    "    \n",
    "handle_long_running(process=do_work, data=4, callback=notify_me)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d2c85",
   "metadata": {},
   "source": [
    "### Map\n",
    "\n",
    "* The `map` function is equivalent to a for loop\n",
    "\n",
    "```map(func, seq)```\n",
    "\n",
    "* func: function to execute\n",
    "* seq, a list of elements to apply `func` to\n",
    "\n",
    "* outputs an array where `func` is applied to every element of `seq` \n",
    "\n",
    "* It's customary to provide func as a lambda function\n",
    "  * Short single expression functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9653cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.900000000000002, 5.4, 179.982, 52.56, 9.18]\n",
      "[18.9, 5.4, 179.98, 52.56, 9.18]\n"
     ]
    }
   ],
   "source": [
    "cost_USD= [10.5, 3.00, 99.99, 29.2, 5.1]\n",
    "cost_CAD = list(map(lambda x: x * 1.8, cost_USD))\n",
    "\n",
    "\n",
    "print(cost_CAD)\n",
    "\n",
    "cost_CAD_rounded  = map(lambda x: round(x, 2), list(cost_CAD))\n",
    "print(list(cost_CAD_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb450a",
   "metadata": {},
   "source": [
    "### Filter\n",
    "\n",
    "* The function equivalent to a `for` loop and a nested `if` statement\n",
    "\n",
    "```filter(func, seq)```\n",
    "* `func`: function that implements some boolean test on each element of `seq` and returns a `Bool`.\n",
    "* `seq`: a list of elements to apply `func` to\n",
    "\n",
    "* Outputs a subset of the elements of `seq` where `func` returned `True`\n",
    "\n",
    "* It's customary to provide func as a lambda function\n",
    "  * Short single expression functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efba0ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n"
     ]
    }
   ],
   "source": [
    "numbers = range(0, 21)\n",
    "even_numbers = list(filter(lambda x: (x % 2) ==0, numbers))\n",
    "print(even_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b30311",
   "metadata": {},
   "source": [
    "### Reduce\n",
    "\n",
    "* This function is part of the `functools` library\n",
    "\n",
    "filter(func, seq)\n",
    "* `func`: a function that operates on two elements at a time and returns one element\n",
    "* `seq`: Sequence of elements to apply `func` to\n",
    "\n",
    "* `filter` reduces the list of `seq` to a single element\n",
    "\n",
    "* It's customary to provide func as a lambda function\n",
    "  * Short single expression functions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e060ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "numbers = [1,2,3,4]\n",
    "print(reduce(lambda x,y: x+y, numbers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f96acdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "1 and 2\n",
      " and 3\n",
      " and 4\n",
      " and 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "numbers = [1,2,3,4,5]\n",
    "print(reduce(lambda x,y: f\"\\n{x} and {y}\\n\", numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44a4b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data = \"\"\"\n",
    "Hi there, Python User!\n",
    "This is a short test to test new functionality.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6571ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi',\n",
       " 'there,',\n",
       " 'Python',\n",
       " 'User!',\n",
       " 'This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'short',\n",
       " 'test',\n",
       " 'to',\n",
       " 'test',\n",
       " 'new',\n",
       " 'functionality.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words  = file_data.split()\n",
    "words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33828131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HI',\n",
       " 'THERE,',\n",
       " 'PYTHON',\n",
       " 'USER!',\n",
       " 'THIS',\n",
       " 'IS',\n",
       " 'A',\n",
       " 'SHORT',\n",
       " 'TEST',\n",
       " 'TO',\n",
       " 'TEST',\n",
       " 'NEW',\n",
       " 'FUNCTIONALITY.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_tokenized_data = list(map(lambda x: x.upper(), words))\n",
    "upper_tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f908e860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poke\n"
     ]
    }
   ],
   "source": [
    "# Common to clean punctuation when counting words \n",
    "\n",
    "import string\n",
    "\n",
    "x = '#PoKe!'\n",
    "trans_table = x.maketrans(\"PK\", \"pk\", string.punctuation) \n",
    "\n",
    "\n",
    "print(x.translate(trans_table))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7039bd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HI',\n",
       " 'THERE',\n",
       " 'pYTHON',\n",
       " 'USER',\n",
       " 'THIS',\n",
       " 'IS',\n",
       " 'A',\n",
       " 'SHORT',\n",
       " 'TEST',\n",
       " 'TO',\n",
       " 'TEST',\n",
       " 'NEW',\n",
       " 'FUNCTIONALITY']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_ponct_upper_tokenized_data =  list(map(lambda x: x.translate(trans_table), upper_tokenized_data))\n",
    "no_ponct_upper_tokenized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a97ca0",
   "metadata": {},
   "source": [
    "### Chaining Iterables\n",
    "\n",
    "* While `map`, `filter` and `reduce`, another function is commonly used to flatten nested structures\n",
    "  * Iterables (lists) are crucial to map-reduce and it's often necessary to flatten nested lists\n",
    "    * Take a list of lists and convert it into a list\n",
    "    \n",
    "```\n",
    "[[1,2], [3,4,5], [6,7,8,9]] -> [1,2,3,4,5,6,7,8,9]\n",
    "```\n",
    "\n",
    "* This can be done using 'itertools.chain()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dffe4b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "a = [1, 2]\n",
    "b = [3, 4, 5]\n",
    "c = [6, 7, 8, 9]\n",
    "\n",
    "list(chain(a, b, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5003ebd9",
   "metadata": {},
   "source": [
    "### Word Counts in Python\n",
    "\n",
    "* How can we implement the word count expressed algorithmically using map-reduce?\n",
    "  * After working on the assignment, you probably understand why need to count words\n",
    " \n",
    "* Count the number of occurrences of each work in \"Pride and Prejudice\", by Jane Austen\n",
    "    * The most downloaded book on project Gutenburg (Library of books in the public domain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c8f1452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line_7: www.gutenberg.org. If you are not located in the United States, you\n",
      "\n",
      "Line_14: \n",
      "\n",
      "Line_21: \n",
      "\n",
      "Line_28: \n",
      "\n",
      "Line_35: \n",
      "\n",
      "Line_42: \n",
      "\n",
      "Line_49:   Chapter 4\n",
      "\n",
      "Line_56: \n",
      "\n",
      "Line_63:   Chapter 11\n",
      "\n",
      "Line_70: \n",
      "\n",
      "Line_77:   Chapter 18\n",
      "\n",
      "Line_84: \n",
      "\n",
      "Line_91:   Chapter 25\n",
      "\n",
      "Line_98: \n",
      "\n",
      "Line_105:   Chapter 32\n",
      "\n",
      "Line_112: \n",
      "\n",
      "Line_119:   Chapter 39\n",
      "\n",
      "Line_126: \n",
      "\n",
      "Line_133:   Chapter 46\n",
      "\n",
      "Line_140: \n",
      "\n",
      "Line_147:   Chapter 53\n",
      "\n",
      "Line_154: \n",
      "\n",
      "Line_161:   Chapter 60\n",
      "\n",
      "Line_168: Chapter 1\n",
      "\n",
      "Line_175:       fixed in the minds of the surrounding families, that he is\n",
      "\n",
      "Line_182:       Mr. Bennet replied that he had not.\n",
      "\n",
      "Line_189:       “Do not you want to know who has taken it?” cried his wife\n",
      "\n",
      "Line_196:       “Why, my dear, you must know, Mrs. Long says that Netherfield is\n",
      "\n",
      "Line_203: \n",
      "\n",
      "Line_210:       “Oh! single, my dear, to be sure! A single man of large fortune;\n",
      "\n",
      "Line_217:       them.”\n",
      "\n",
      "Line_224: \n",
      "\n",
      "Line_231:       beauty, but I do not pretend to be anything extraordinary now.\n",
      "\n",
      "Line_238:       comes into the neighbourhood.”\n",
      "\n",
      "Line_245:       know, they visit no newcomers. Indeed you must go, for it will be\n",
      "\n",
      "Line_252:       little Lizzy.”\n",
      "\n",
      "Line_259:       “They have none of them much to recommend them,” replied he;\n",
      "\n",
      "Line_266: \n",
      "\n",
      "Line_273:       “But I hope you will get over it, and live to see many young men\n",
      "\n",
      "Line_280:       visit them all.”\n",
      "\n",
      "Line_287:       temper. When she was discontented, she fancied herself nervous.\n",
      "\n",
      "Line_294: Chapter 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "url = 'https://www.gutenberg.org/files/1342/1342-0.txt'\n",
    "\n",
    "dest_file_name = str(uuid.uuid4())+\".txt\"\n",
    "\n",
    "urlretrieve(url, dest_file_name)\n",
    "\n",
    "i= 1\n",
    "for line in open(dest_file_name):\n",
    "    if i % 7 == 0:\n",
    "        print(f\"Line_{i}: {line}\")\n",
    "    if i % 300 == 0:\n",
    "        break\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23059d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 123 Release Date: June, 1998 [eBook #1342]\n",
      "Removing digits:  Release Date: June,  [eBook #]\n",
      "Removing non words:  Release Date June eBook \n",
      "['RELEASE', 'DATE', 'JUNE', 'EBOOK']\n"
     ]
    }
   ],
   "source": [
    "# Another useful functio to manipulate dat is re\n",
    "# Regular expressions library.\n",
    "# Excellent tutorial linked from Miro (week-5)\n",
    "\n",
    "import re\n",
    "original_sentence = \"123 Release Date: June, 1998 [eBook #1342]\"\n",
    "print(f\"Original: {original_sentence}\")\n",
    "a = re.sub('\\d+', '', original_sentence)\n",
    "print(f\"Removing digits: {a}\")\n",
    "b = re.sub('[\\W]+', ' ', a)\n",
    "print(f\"Removing non words: {b}\")\n",
    "c = b.upper().split()\n",
    "print(c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "634a4235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33c15465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coun the numeber of unique workds in dest_file_name\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def clean_split_line(l):\n",
    "    a = re.sub('\\d+', '', line)\n",
    "    b = re.sub('[\\W]+', ' ', a)\n",
    "    return b.upper().split()\n",
    "\n",
    "tally = defaultdict(int)\n",
    "in_file = open(dest_file_name)\n",
    "for line in in_file:\n",
    "    for word in clean_split_line(line):\n",
    "            tally[word] += 1 \n",
    "                 \n",
    "in_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfd31676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('THE', 4521),\n",
       " ('TO', 4245),\n",
       " ('OF', 3734),\n",
       " ('AND', 3657),\n",
       " ('HER', 2202),\n",
       " ('I', 2048),\n",
       " ('A', 2006),\n",
       " ('IN', 1939),\n",
       " ('WAS', 1846),\n",
       " ('SHE', 1691),\n",
       " ('THAT', 1555),\n",
       " ('IT', 1550),\n",
       " ('NOT', 1449),\n",
       " ('YOU', 1401),\n",
       " ('HE', 1328),\n",
       " ('HIS', 1257),\n",
       " ('BE', 1256),\n",
       " ('AS', 1193),\n",
       " ('HAD', 1172),\n",
       " ('WITH', 1098),\n",
       " ('FOR', 1084),\n",
       " ('BUT', 1006),\n",
       " ('IS', 879),\n",
       " ('HAVE', 846),\n",
       " ('AT', 802),\n",
       " ('MR', 784),\n",
       " ('HIM', 752),\n",
       " ('ON', 729),\n",
       " ('MY', 702),\n",
       " ('S', 664),\n",
       " ('BY', 663),\n",
       " ('ALL', 640),\n",
       " ('ELIZABETH', 634),\n",
       " ('THEY', 599),\n",
       " ('SO', 593),\n",
       " ('WERE', 565),\n",
       " ('WHICH', 546),\n",
       " ('COULD', 526),\n",
       " ('BEEN', 513),\n",
       " ('FROM', 508),\n",
       " ('NO', 501),\n",
       " ('VERY', 490),\n",
       " ('THIS', 488),\n",
       " ('WHAT', 478),\n",
       " ('WOULD', 467),\n",
       " ('YOUR', 446),\n",
       " ('THEIR', 439),\n",
       " ('THEM', 429),\n",
       " ('ME', 427),\n",
       " ('DARCY', 417)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(tally.items(), key= lambda item: item[1], reverse=True)[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41be389",
   "metadata": {},
   "source": [
    "* Recall that the approch above has two issues:\n",
    "1. reading very large files from disk can be slow\n",
    "2. Since the counts dictionary is stored in a RAM, the data structure cannot scale to be larger that available RAM.\n",
    "  * The program will run fairly quickly when the dictionary is in cache\n",
    "  * You will notice a slow down in execution when the data is stored in RAM\n",
    "  * Slows down substantially when moved to disk.\n",
    "   \n",
    "3. No incentive in parallelizing the program since the RAM and disk are the bottlenecks  \n",
    "\n",
    "![](https://nyu-cds.github.io/python-bigdata/fig/02-performance.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b94a56",
   "metadata": {},
   "source": [
    "# Map Reduce Hello World\n",
    "\n",
    "\n",
    "* Approach:\n",
    "  * Each machine parses a file chunk from which it extracts and counts words\n",
    " * Does not require a central data structure\n",
    "   * Results for different keys are stored on different machines\n",
    "   * Can be directly written to file.\n",
    " \n",
    "* Recall that the steps are:\n",
    "1 `map` to associate some intermediate value with a key\n",
    "2. shuffle (hashing) operation to group the same keys in the same reduce operation\n",
    "3. `reduce` step that processes groups of intermediate results with the same map `key`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26e920b",
   "metadata": {},
   "source": [
    "### Map Step\n",
    "\n",
    "* Initialize the words with the default value of 1.\n",
    "  * Here, we assume that the first step is to map the list of words\n",
    "    * In real life, the first map is an operation on lines to generate a list of words\n",
    "  e.g.:\n",
    "```\n",
    "[(1, line_1_list_of_words), (2, line_2_list_of_words), (3, line_3_list_of_words) ... ]\n",
    "```\n",
    "\n",
    "* Also, this assumes that the chunk we are reading either fits in RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdc05175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('and', 1), ('she', 1), ('was', 1), ('delayed', 1), ('longer', 1), ('and', 1), ('was', 1), ('no', 1), ('longer', 1), ('interested', 1)]\n"
     ]
    }
   ],
   "source": [
    "words = \"and she was delayed longer and was no longer interested\".split()\n",
    "mapping = list(map((lambda x : (x, 1)), words))\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92188c0",
   "metadata": {},
   "source": [
    "### Shuffling and Partition Data\n",
    "\n",
    "* Assign values that have the same key to the same reduce operation\n",
    "  * Use the hashing to assign a key to a reduce operation\n",
    "\n",
    "* Use the `hash() % n`, where n is the number of partitions (reduce operations we desire)\n",
    "  * Any word will be assigned to a single machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d7052a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1347818577769608645, 7159054052798980931, -3455425074695774470, -5686480761053666514, 3633005027481694218, 1347818577769608645, -3455425074695774470, -677858683092840762, 3633005027481694218, 6672054164431875280]\n",
      "\n",
      "\n",
      "\n",
      "[(1347818577769608645, ('and', 1)), (7159054052798980931, ('she', 1)), (-3455425074695774470, ('was', 1)), (-5686480761053666514, ('delayed', 1)), (3633005027481694218, ('longer', 1)), (1347818577769608645, ('and', 1)), (-3455425074695774470, ('was', 1)), (-677858683092840762, ('no', 1)), (3633005027481694218, ('longer', 1)), (6672054164431875280, ('interested', 1))]\n"
     ]
    }
   ],
   "source": [
    "keys = list(map(lambda x: hash(x[0]), mapping))\n",
    "\n",
    "print(keys)\n",
    "print(\"\\n\\n\")\n",
    "assignments = list(zip(keys, mapping))\n",
    "print(assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4898e5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-8553623896164343587: [('and', 1), ('and', 1)],\n",
       " 6074181533842555324: [('she', 1)],\n",
       " 1234660841907172634: [('was', 1), ('was', 1)],\n",
       " -1466414117393854651: [('delayed', 1)],\n",
       " 4426157748255515329: [('longer', 1), ('longer', 1)],\n",
       " 3193805951125457928: [('no', 1)],\n",
       " 3999382940960817353: [('interested', 1)]}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitions = {}\n",
    "for key, val in assignments:\n",
    "    partitions.setdefault(key, []).append(val)\n",
    "partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bfebcdcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1347818577769608645, 'and'): [1, 1],\n",
       " (7159054052798980931, 'she'): [1],\n",
       " (-3455425074695774470, 'was'): [1, 1],\n",
       " (-5686480761053666514, 'delayed'): [1],\n",
       " (3633005027481694218, 'longer'): [1, 1],\n",
       " (-677858683092840762, 'no'): [1],\n",
       " (6672054164431875280, 'interested'): [1]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitions = {}\n",
    "for key, val in assignments:\n",
    "    partitions.setdefault((key, val[0]),  []).append(val[1])\n",
    "partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac24b68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1347818577769608645, 'and'): 0,\n",
       " (7159054052798980931, 'she'): 2,\n",
       " (-3455425074695774470, 'was'): 1,\n",
       " (-5686480761053666514, 'delayed'): 0,\n",
       " (3633005027481694218, 'longer'): 0,\n",
       " (-677858683092840762, 'no'): 0,\n",
       " (6672054164431875280, 'interested'): 1}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_jobs = {}\n",
    "for k in partitions.keys():\n",
    "    reduce_jobs[k] = abs(k[0]) % 3 \n",
    "reduce_jobs    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae82c892",
   "metadata": {},
   "source": [
    "### Reducing\n",
    "\n",
    "* Count the number of values assigned to each key\n",
    "  * Sum the values occuring withing the same key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "076c7766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1], [1], [1, 1], [1], [1, 1], [1], [1]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call that these operation occurr on different nodes\n",
    "# as assigned using the reduce_jobs variable\n",
    "data = list(map( lambda x: x, partitions.values()))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d49abb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1347818577769608645, 'and'): [1, 1],\n",
       " (7159054052798980931, 'she'): [1],\n",
       " (-3455425074695774470, 'was'): [1, 1],\n",
       " (-5686480761053666514, 'delayed'): [1],\n",
       " (3633005027481694218, 'longer'): [1, 1],\n",
       " (-677858683092840762, 'no'): [1],\n",
       " (6672054164431875280, 'interested'): [1]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0c6a4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 2),\n",
       " ('she', 1),\n",
       " ('was', 2),\n",
       " ('delayed', 1),\n",
       " ('longer', 2),\n",
       " ('no', 1),\n",
       " ('interested', 1)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: (x[0][1],reduce(lambda x,y : x+y, x[1])),  partitions.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5801f105",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "* The above may seem complicated, but it's an artifact of trying to implement a map reduce in a system that's not designed for this paradigm\n",
    "\n",
    "  * The reduce is complicated by the fact that we need to manually grab the values associated with each key\n",
    "  * and the fact that we nest reduce within a map\n",
    "\n",
    "* In a map reduce environment, each chunk server deals with one or more chunks at a time.\n",
    "  * The entire file is never read in memory \n",
    "  * The real map-reduce program is not affected by the same caching issues as the simple version.\n",
    " \n",
    "\n",
    "* Map Reduce is clearly not a general-purpose framework that can handle any problem\n",
    "  * Many problems can be broken represented with the map-reduce paradigm.\n",
    "    * example of \"join\" in the second assignment\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
